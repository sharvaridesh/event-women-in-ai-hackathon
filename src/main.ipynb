{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Library/Developer/CommandLineTools/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install -U pymilvus unsloth --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets \"pymilvus[model]\" langchain_milvus langchain_openai langchain_community langchain_huggingface pandas sentence-transformers openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio fitz PyMuPDF python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "from pymilvus import MilvusClient\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain_milvus import Milvus, Zilliz\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_vars():\n",
    "    # Load environment variables from .env file.\n",
    "    dotenv_path = 'security_keys.env'\n",
    "    dotenv.load_dotenv(dotenv_path=dotenv_path)\n",
    "    openai_api_key = os.getenv('OPENAIAPI_KEY')\n",
    "    return openai_api_key\n",
    "\n",
    "openai_api_key = load_env_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load hugging face linkedin job postings dataset\n",
    "ds = load_dataset(\"datastax/linkedin_job_listings\")\n",
    "df = pd.read_csv(\"hf://datasets/datastax/linkedin_job_listings/postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dataframe(df):\n",
    "  # Calculate the percentage of missing values in each column\n",
    "  missing_percent = df.isnull().mean() * 100\n",
    "\n",
    "  # Drop columns where more than 70% of the values are NaN\n",
    "  df_cleaned = df.loc[:, missing_percent <= 70]\n",
    "\n",
    "    # Select relevant columns for embedding\n",
    "  df_cleaned['text_to_embed'] = df_cleaned[['title', 'company_name', 'description', 'location',\n",
    "                                            'formatted_experience_level']].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "  # Clean the text (lowercasing and removing special characters)\n",
    "  df_cleaned['text_to_embed'] = df_cleaned['text_to_embed'].str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "  return df_cleaned\n",
    "\n",
    "df_cleaned = preprocessing_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(df_cleaned):\n",
    "  # Load embedding model\n",
    "  model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "  # Generate embeddings for job postings\n",
    "  df_cleaned['embeddings'] = df_cleaned['text_to_embed'].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "  # Connect to Milvus client given URI\n",
    "  milvus_client = MilvusClient(uri=\"jobposting_demo.db\")\n",
    "  return model, milvus_client, df_cleaned\n",
    "\n",
    "model, milvus_client, df_cleaned = generate_embeddings(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_milvus_schema_and_collection(milvus_client, collection_name = \"job_postings_linkedin\", dim=384, metric_type=\"COSINE\"):\n",
    "  # Create schema and collection\n",
    "  dim = dim\n",
    "  collection_name = collection_name\n",
    "\n",
    "  # Define the schema for the job postings collection\n",
    "  fields = [\n",
    "      FieldSchema(name=\"job_id\", dtype=DataType.INT64, is_primary=True),\n",
    "      FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=255),\n",
    "      FieldSchema(name=\"location\", dtype=DataType.VARCHAR, max_length=255),\n",
    "      FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=len(df_cleaned['embeddings'][0]))\n",
    "  ]\n",
    "\n",
    "  schema = CollectionSchema(fields, description=\"Job Postings Embeddings\")\n",
    "\n",
    "  if milvus_client.has_collection(collection_name=collection_name):\n",
    "      milvus_client.drop_collection(collection_name=collection_name)\n",
    "\n",
    "  milvus_params = milvus_client.prepare_index_params()\n",
    "  milvus_params.add_index(field_name=\"embedding\", index_type=\"AUTOINDEX\", metric_type=metric_type)\n",
    "\n",
    "  milvus_client.create_collection(\n",
    "      collection_name,\n",
    "      dim,\n",
    "      primary_field_name=\"job_id\",\n",
    "      vector_field_name=\"embedding\",\n",
    "      index_params=milvus_params,\n",
    "      auto_id=True,\n",
    "      schema=schema,\n",
    "  )\n",
    "\n",
    "  print(milvus_client.list_collections())\n",
    "  return schema, collection_check\n",
    "\n",
    "create_milvus_schema_and_collection(milvus_client, collection_name = \"job_postings_linkedin\", dim=384, metric_type=\"COSINE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_milvus(milvus_client, df_cleaned):\n",
    "  insert_data = [{\"job_id\": jid, \"title\": title, \"location\": loc, \"embedding\": emb} for jid, title, loc, emb in zip(df_cleaned['job_id'].astype(int).tolist(),\n",
    "      df_cleaned['title'].astype(str).tolist(),\n",
    "      df_cleaned['location'].astype(str).tolist(),\n",
    "      df_cleaned['embeddings'].tolist())]\n",
    "\n",
    "  # Insert data into Milvus\n",
    "  try:\n",
    "    milvus_client.insert(\n",
    "        collection_name=collection_name,\n",
    "        data=insert_data)\n",
    "    print(f\"Inserted {len(df_cleaned)} records into Milvus.\")\n",
    "    return True\n",
    "  except:\n",
    "    return \"Error in pushing data to milvus collection\"\n",
    "\n",
    "insert_data_into_milvus(milvus_client, df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_jobs(milvus_client, resume_text, k=5):\n",
    "  search_params = {\"metric_type\": \"\", \"params\": {}}\n",
    "  resume_embedding = model.encode(resume_text).tolist()\n",
    "\n",
    "  results = milvus_client.search(\n",
    "      collection_name=collection_name,\n",
    "      data=[resume_embedding],\n",
    "      search_params=search_params,\n",
    "      limit=k,\n",
    "      output_fields=[\"job_id\", \"title\", \"location\"]\n",
    "  )\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_job_explanations(milvus_client, resume_text, k=5):\n",
    "    jobs = search_jobs(milvus_client, resume_text, k)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", api_key=os.getenv('OPENAIAPI_KEY'))\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"resume\", \"title\", \"location\"],\n",
    "        template=(\n",
    "            \"Given the candidate's resume: {resume}, explain why the role {title} \"\n",
    "            \"in {location} is a good fit for them.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    for job in jobs[0]:\n",
    "        title = job['entity']['title']\n",
    "        location = job['entity']['location']\n",
    "        explanation = chain.run(resume=resume_text, title=title, location=location)\n",
    "        print(f\"Job ID: {job['entity']['job_id']}, Title: {title}, Location: {location}\")\n",
    "        print(f\"Explanation: {explanation}\\n\")\n",
    "\n",
    "# Input resume text and run the pipeline\n",
    "resume_text = input(\"Enter your resume text: \")\n",
    "generate_job_explanations(milvus_client, resume_text, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
